# üá∫üá¶ Lapa LLM Integration Guide

## –û—Ñ—ñ—Ü—ñ–π–Ω–∏–π —Å–ø–æ—Å—ñ–± –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è Lapa LLM –¥–ª—è Yana.Diia.AI

### üü¢ HuggingFace Inference API

**API Endpoint:**

```
https://api-inference.huggingface.co/models/lapa-ai/lapa-7b
```

---

## Python Integration (Backend)

### –ë–∞–∑–æ–≤–∏–π –ø—Ä–∏–∫–ª–∞–¥

```python
from huggingface_hub import InferenceApi

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
lapa = InferenceApi(repo_id="lapa-ai/lapa-7b")

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è BRD
result = lapa(inputs="–ó–≥–µ–Ω–µ—Ä—É–π BRD –¥–ª—è –¥–µ—Ä–∂–∞–≤–Ω–æ—ó –ø–æ—Å–ª—É–≥–∏ —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó –§–û–ü")
print(result)
```

### –ó –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

```python
from huggingface_hub import InferenceApi

lapa = InferenceApi(
    repo_id="lapa-ai/lapa-7b",
    token="hf_yourapitoken"  # Optional –¥–ª—è –±—ñ–ª—å—à–µ –∑–∞–ø–∏—Ç—ñ–≤
)

response = lapa(
    inputs="–°—Ç–≤–æ—Ä–∏ acceptance criteria –¥–ª—è –¥–µ—Ä–∂–ø–æ—Å–ª—É–≥–∏ –ø–æ—à—É–∫—É –ø—ñ–ª—å–≥",
    parameters={
        "max_length": 1024,
        "temperature": 0.8,
        "top_p": 0.9
    }
)
```

### –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –≤ Yana Backend

```python
# backend/services/lapa_service.py
import os
from huggingface_hub import InferenceApi

class LapaService:
    def __init__(self):
        self.api = InferenceApi(
            repo_id="lapa-ai/lapa-7b",
            token=os.getenv("HUGGINGFACE_API_TOKEN")
        )
    
    def generate_brd(self, service_description: str) -> str:
        """Generate BRD from service description in Ukrainian"""
        prompt = f"–ó–≥–µ–Ω–µ—Ä—É–π –¥–µ—Ç–∞–ª—å–Ω–∏–π BRD –¥–ª—è –¥–µ—Ä–∂–∞–≤–Ω–æ—ó –ø–æ—Å–ª—É–≥–∏: {service_description}"
        result = self.api(inputs=prompt, parameters={"max_length": 2048})
        return result[0]["generated_text"]
    
    def generate_acceptance_criteria(self, user_story: str) -> list:
        """Generate acceptance criteria from user story"""
        prompt = f"–°—Ç–≤–æ—Ä–∏ acceptance criteria –¥–ª—è: {user_story}"
        result = self.api(inputs=prompt, parameters={"max_length": 1024})
        return result[0]["generated_text"].split("\n")
```

---

## Node.js / JavaScript Integration (Frontend)

### Fetch API

```javascript
async function generateWithLapa(prompt) {
  const response = await fetch('https://api-inference.huggingface.co/models/lapa-ai/lapa-7b', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer hf_yourapitoken',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({ 
      inputs: prompt,
      parameters: {
        max_length: 1024,
        temperature: 0.8
      }
    })
  });
  
  const result = await response.json();
  return result[0].generated_text;
}

// –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
const brd = await generateWithLapa("–ó–≥–µ–Ω–µ—Ä—É–π BRD –¥–ª—è –µ-–º–∞–ª—è—Ç–∫–æ –ø–æ—Å–ª—É–≥–∏");
```

### Aixos

```javascript
import axios from 'axios';

const lapaAPI = axios.create({
  baseURL: 'https://api-inference.huggingface.co/models/lapa-ai',
  headers: {
    'Authorization': `Bearer ${process.env.HUGGINGFACE_API_TOKEN}`,
    'Content-Type': 'application/json'
  }
});

async function generateBRD(description) {
  const { data } = await lapaAPI.post('/lapa-7b', {
    inputs: `–°—Ç–≤–æ—Ä–∏ BRD –¥–ª—è: ${description}`,
    parameters: { max_length: 2048, temperature: 0.7 }
  });
  
  return data[0].generated_text;
}
```

---

## Environment Variables

### Backend (.env)

```bash
HUGGINGFACE_API_TOKEN=hf_your_token_here
LAPA_MODEL_ID=lapa-ai/lapa-7b
LAPA_MAX_LENGTH=2048
LAPA_TEMPERATURE=0.8
```

### Frontend (.env.local)

```bash
NEXT_PUBLIC_HUGGINGFACE_API_TOKEN=hf_your_token_here
```

---

## API Limits & Credits

### –ë–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ

- 1000-2000 –∑–∞–ø–∏—Ç—ñ–≤/–≥–æ–¥–∏–Ω—É
- –î–æ 10,000 –∑–∞–ø–∏—Ç—ñ–≤/–¥–æ–±—É –∑ –∞–∫–∞—É–Ω—Ç–∞
- –î–ª—è hackathon —Ü–µ –±—ñ–ª—å—à –Ω—ñ–∂ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ

### –ü—Ä–∏ –ø–µ—Ä–µ–≤–∏—â–µ–Ω–Ω—ñ

- –ü–æ—á–µ–∫–∞–π 10 —Ö–≤–∏–ª–∏–Ω
- –ê–±–æ –æ—Ç—Ä–∏–º–∞–π HuggingFace PRO (–Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ –¥–ª—è —Ö–∞–∫–∞—Ç–æ–Ω—É)

---

## –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –≤ Yana.Diia.AI

### Use Cases

1. **BRD Generation (—É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é):**

   ```python
   brd = lapa_service.generate_brd("–ü–æ—Å–ª—É–≥–∞ –¥–ª—è –≤–∏–ø–ª–∞—Ç–∏ –¥–æ–ø–æ–º–æ–≥–∏ –í–ü–û")
   ```

2. **User Stories:**

   ```python
   user_story = lapa_service.generate_user_story(brd_text)
   ```

3. **Acceptance Criteria:**

   ```python
   criteria = lapa_service.generate_acceptance_criteria(user_story)
   ```

4. **Flow Descriptions:**

   ```python
   flow_desc = lapa_service.generate_flow_description(service_name)
   ```

### –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

```
User Input (BRD) 
  ‚Üì
Lapa LLM (Ukrainian text generation)
  ‚Üì
CodeMie SDK (Flow + UI generation)
  ‚Üì
Yana Output (User Stories + UI mockups)
```

---

## Quick Test

### Web Interface

–®–≤–∏–¥–∫–æ –ø—Ä–æ—Ç–µ—Å—Ç—É–≤–∞—Ç–∏: <https://huggingface.co/spaces/lapa-ai/lapa-chat>

### Local Test

```python
from huggingface_hub import InferenceApi

lapa = InferenceApi(repo_id="lapa-ai/lapa-7b")
result = lapa(inputs="–ü—Ä–∏–≤—ñ—Ç! –°—Ç–≤–æ—Ä–∏ –ø—Ä–∏–∫–ª–∞–¥ BRD –¥–ª—è –¥–µ—Ä–∂–ø–æ—Å–ª—É–≥–∏")
print(result[0]["generated_text"])
```

---

## Benefits for Yana

- ‚úÖ **–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞** - native Ukrainian text generation
- ‚úÖ **Open Source** - –º–æ–∂–Ω–∞ –ø–æ–∫–∞–∑–∞—Ç–∏ –Ω–∞ Demo Day
- ‚úÖ **Free for hackathon** - no costs
- ‚úÖ **–û—Ñ—ñ—Ü—ñ–π–Ω–∏–π API** - stable infrastructure
- ‚úÖ **–ö–æ–º–±—ñ–Ω—É—î—Ç—å—Å—è –∑ CodeMie** - best of both worlds

---

## Next Steps

1. –î–æ–¥–∞—Ç–∏ `lapa_service.py` –≤ `backend/services/`
2. –û–Ω–æ–≤–∏—Ç–∏ `.env` –∑ HuggingFace token
3. –Ü–Ω—Ç–µ–≥—Ä—É–≤–∞—Ç–∏ –≤ `/api/generate` endpoint
4. –¢–µ—Å—Ç—É–≤–∞—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—é BRD —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é
5. –ü–æ–∫–∞–∑–∞—Ç–∏ –Ω–∞ Demo Day —è–∫ "ukrainian-first AI"

---

**–ì–æ—Ç–æ–≤–æ –¥–ª—è —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó! üöÄüá∫üá¶**
